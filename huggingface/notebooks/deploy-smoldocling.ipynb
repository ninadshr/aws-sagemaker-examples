{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deploy SmolDocling on AWS SageMaker\n",
    "\n",
    "This notebook demonstrates how to deploy DS4SD's SmolDocling model on Amazon SageMaker for document understanding and conversion.\n",
    "\n",
    "## What is SmolDocling?\n",
    "SmolDocling is a vision-language model designed for document understanding tasks:\n",
    "- Convert document images to Markdown, HTML, or DocTags\n",
    "- Extract structured content from PDFs, scans, and images\n",
    "- Preserve document layout and formatting\n",
    "- Support for tables, figures, and complex layouts\n",
    "\n",
    "## Prerequisites\n",
    "- AWS Account with SageMaker access\n",
    "- IAM role with SageMaker permissions\n",
    "- Document images for testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup and Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import sagemaker\n",
    "from sagemaker.huggingface import HuggingFaceModel\n",
    "import json\n",
    "import base64\n",
    "from pathlib import Path\n",
    "import tarfile\n",
    "import os\n",
    "\n",
    "# Configuration\n",
    "role = sagemaker.get_execution_role()\n",
    "sess = sagemaker.Session()\n",
    "region = sess.boto_region_name\n",
    "\n",
    "print(f\"SageMaker role: {role}\")\n",
    "print(f\"Region: {region}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Prepare Custom Inference Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create model artifact with custom inference code\n",
    "code_dir = \"../smoldocling_code\"\n",
    "model_artifact = \"model.tar.gz\"\n",
    "\n",
    "print(f\"Creating model artifact from {code_dir}...\")\n",
    "with tarfile.open(model_artifact, \"w:gz\") as tar:\n",
    "    tar.add(code_dir, arcname=\"code\")\n",
    "\n",
    "# Upload to S3\n",
    "s3_client = boto3.client(\"s3\")\n",
    "bucket = sess.default_bucket()\n",
    "prefix = \"smoldocling-model\"\n",
    "s3_path = f\"s3://{bucket}/{prefix}/{model_artifact}\"\n",
    "\n",
    "print(f\"Uploading to {s3_path}...\")\n",
    "s3_client.upload_file(model_artifact, bucket, f\"{prefix}/{model_artifact}\")\n",
    "\n",
    "# Clean up local artifact\n",
    "os.remove(model_artifact)\n",
    "print(\"✓ Model artifact uploaded\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Deploy the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model configuration\n",
    "hub = {\n",
    "    \"HF_MODEL_ID\": \"ds4sd/docling-project__SmolDocling-v1.0\",\n",
    "    \"HF_TASK\": \"image-to-text\",\n",
    "}\n",
    "\n",
    "# Create Hugging Face Model\n",
    "huggingface_model = HuggingFaceModel(\n",
    "    model_data=s3_path,\n",
    "    role=role,\n",
    "    transformers_version=\"4.37\",\n",
    "    pytorch_version=\"2.1\",\n",
    "    py_version=\"py310\",\n",
    "    env=hub,\n",
    ")\n",
    "\n",
    "print(\"Model configuration complete\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Deploy the model (this takes 5-10 minutes)\n",
    "predictor = huggingface_model.deploy(\n",
    "    initial_instance_count=1,\n",
    "    instance_type=\"ml.g5.2xlarge\",\n",
    "    endpoint_name=\"smoldocling-endpoint\",\n",
    "    container_startup_health_check_timeout=600,\n",
    ")\n",
    "\n",
    "print(f\"✓ Endpoint deployed: {predictor.endpoint_name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Test the Endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function to load and encode image\n",
    "def encode_image(image_path):\n",
    "    with open(image_path, \"rb\") as f:\n",
    "        image_bytes = f.read()\n",
    "    return base64.b64encode(image_bytes).decode(\"utf-8\")\n",
    "\n",
    "# Test with a document image\n",
    "image_path = \"your_document.png\"  # Replace with your image path\n",
    "\n",
    "if Path(image_path).exists():\n",
    "    image_base64 = encode_image(image_path)\n",
    "    \n",
    "    payload = {\n",
    "        \"image\": image_base64,\n",
    "        \"prompt\": \"Convert this page to docling.\",\n",
    "        \"output_format\": \"markdown\",  # Options: markdown, html, doctags\n",
    "        \"max_new_tokens\": 8192\n",
    "    }\n",
    "    \n",
    "    # Initialize runtime client\n",
    "    runtime = boto3.client(\"sagemaker-runtime\")\n",
    "    \n",
    "    response = runtime.invoke_endpoint(\n",
    "        EndpointName=predictor.endpoint_name,\n",
    "        ContentType=\"application/json\",\n",
    "        Body=json.dumps(payload)\n",
    "    )\n",
    "    \n",
    "    result = json.loads(response[\"Body\"].read().decode())\n",
    "    print(\"\\n=== Markdown Output ===\")\n",
    "    print(result.get(\"markdown\", \"\"))\n",
    "    print(\"\\n=== DocTags ===\")\n",
    "    print(result.get(\"doctags\", \"\")[:500] + \"...\")\n",
    "else:\n",
    "    print(f\"Image not found: {image_path}\")\n",
    "    print(\"Please provide a document image to test.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Document Processing Use Cases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example 1: Convert to HTML\n",
    "payload = {\n",
    "    \"image\": image_base64,\n",
    "    \"prompt\": \"Convert this page to docling.\",\n",
    "    \"output_format\": \"html\",\n",
    "    \"max_new_tokens\": 8192\n",
    "}\n",
    "\n",
    "response = runtime.invoke_endpoint(\n",
    "    EndpointName=predictor.endpoint_name,\n",
    "    ContentType=\"application/json\",\n",
    "    Body=json.dumps(payload)\n",
    ")\n",
    "\n",
    "result = json.loads(response[\"Body\"].read().decode())\n",
    "print(\"\\n=== HTML Output ===\")\n",
    "print(result.get(\"html\", \"\")[:500] + \"...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example 2: Extract DocTags only (structured format)\n",
    "payload = {\n",
    "    \"image\": image_base64,\n",
    "    \"prompt\": \"Convert this page to docling.\",\n",
    "    \"output_format\": \"doctags\",\n",
    "    \"max_new_tokens\": 8192\n",
    "}\n",
    "\n",
    "response = runtime.invoke_endpoint(\n",
    "    EndpointName=predictor.endpoint_name,\n",
    "    ContentType=\"application/json\",\n",
    "    Body=json.dumps(payload)\n",
    ")\n",
    "\n",
    "result = json.loads(response[\"Body\"].read().decode())\n",
    "print(\"\\n=== DocTags Output ===\")\n",
    "print(result.get(\"doctags\", \"\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Batch Processing Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process multiple documents\n",
    "document_dir = Path(\"documents\")  # Directory with document images\n",
    "\n",
    "if document_dir.exists():\n",
    "    results = []\n",
    "    \n",
    "    for image_file in document_dir.glob(\"*.png\"):\n",
    "        print(f\"Processing {image_file.name}...\")\n",
    "        \n",
    "        image_base64 = encode_image(str(image_file))\n",
    "        payload = {\n",
    "            \"image\": image_base64,\n",
    "            \"prompt\": \"Convert this page to docling.\",\n",
    "            \"output_format\": \"markdown\",\n",
    "            \"max_new_tokens\": 8192\n",
    "        }\n",
    "        \n",
    "        response = runtime.invoke_endpoint(\n",
    "            EndpointName=predictor.endpoint_name,\n",
    "            ContentType=\"application/json\",\n",
    "            Body=json.dumps(payload)\n",
    "        )\n",
    "        \n",
    "        result = json.loads(response[\"Body\"].read().decode())\n",
    "        results.append({\n",
    "            \"filename\": image_file.name,\n",
    "            \"markdown\": result.get(\"markdown\", \"\"),\n",
    "            \"doctags\": result.get(\"doctags\", \"\")\n",
    "        })\n",
    "    \n",
    "    print(f\"\\n✓ Processed {len(results)} documents\")\n",
    "else:\n",
    "    print(f\"Directory not found: {document_dir}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Performance Monitoring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get endpoint metrics from CloudWatch\n",
    "import datetime\n",
    "\n",
    "cloudwatch = boto3.client('cloudwatch')\n",
    "\n",
    "end_time = datetime.datetime.utcnow()\n",
    "start_time = end_time - datetime.timedelta(hours=1)\n",
    "\n",
    "metrics = cloudwatch.get_metric_statistics(\n",
    "    Namespace='AWS/SageMaker',\n",
    "    MetricName='ModelLatency',\n",
    "    Dimensions=[\n",
    "        {'Name': 'EndpointName', 'Value': predictor.endpoint_name},\n",
    "        {'Name': 'VariantName', 'Value': 'AllTraffic'}\n",
    "    ],\n",
    "    StartTime=start_time,\n",
    "    EndTime=end_time,\n",
    "    Period=300,\n",
    "    Statistics=['Average', 'Maximum']\n",
    ")\n",
    "\n",
    "print(\"Model Latency Metrics:\")\n",
    "for datapoint in metrics['Datapoints']:\n",
    "    print(f\"  Time: {datapoint['Timestamp']}\")\n",
    "    print(f\"  Average: {datapoint.get('Average', 0):.2f}ms\")\n",
    "    print(f\"  Maximum: {datapoint.get('Maximum', 0):.2f}ms\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Cleanup (Optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete the endpoint to avoid charges\n",
    "# predictor.delete_endpoint()\n",
    "# print(\"Endpoint deleted\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
